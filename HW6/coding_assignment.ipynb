{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:51.161763Z",
          "iopub.status.busy": "2022-01-22T15:55:51.161511Z",
          "iopub.status.idle": "2022-01-22T15:55:51.165623Z",
          "shell.execute_reply": "2022-01-22T15:55:51.164626Z",
          "shell.execute_reply.started": "2022-01-22T15:55:51.161734Z"
        },
        "id": "JalH-YG0dIAE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import spacy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egHUwzF3dIAI"
      },
      "source": [
        "# Import Required Libraries & Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:51.178773Z",
          "iopub.status.busy": "2022-01-22T15:55:51.178323Z",
          "iopub.status.idle": "2022-01-22T15:55:52.913605Z",
          "shell.execute_reply": "2022-01-22T15:55:52.912893Z",
          "shell.execute_reply.started": "2022-01-22T15:55:51.178736Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "KlgKEhNbdIAM",
        "outputId": "c8910132-0efa-46e3-a11e-7ca715798666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "5  Probably my all-time favorite movie, a story o...  positive\n",
              "6  I sure would like to see a resurrection of a u...  positive\n",
              "7  This show was an amazing, fresh & innovative i...  negative\n",
              "8  Encouraged by the positive comments about this...  negative\n",
              "9  If you like original gut wrenching laughter yo...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24c95572-86bf-4755-a0e6-854411d552eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I sure would like to see a resurrection of a u...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Encouraged by the positive comments about this...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>If you like original gut wrenching laughter yo...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24c95572-86bf-4755-a0e6-854411d552eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24c95572-86bf-4755-a0e6-854411d552eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24c95572-86bf-4755-a0e6-854411d552eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#importing the training data\n",
        "df=pd.read_csv('IMDB Dataset.csv')\n",
        "print(df.shape)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53iQmZ0KdIAP"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:52.915240Z",
          "iopub.status.busy": "2022-01-22T15:55:52.914817Z",
          "iopub.status.idle": "2022-01-22T15:55:52.931074Z",
          "shell.execute_reply": "2022-01-22T15:55:52.930198Z",
          "shell.execute_reply.started": "2022-01-22T15:55:52.915202Z"
        },
        "id": "UA-gdr_8dIAP"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "sentiment : 0 = negative, 1 = positive \n",
        "use the following to get the sentiment of a sentence :  \n",
        "sentiment = 0 if sentiment is negative else 1\n",
        "\n",
        "\n",
        "use np.where to get the sentiment of a sentence :\n",
        "\"\"\"\n",
        "df['sentiment'] = np.where(df['sentiment'] == 'positive', 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:52.933556Z",
          "iopub.status.busy": "2022-01-22T15:55:52.933295Z",
          "iopub.status.idle": "2022-01-22T15:55:52.942961Z",
          "shell.execute_reply": "2022-01-22T15:55:52.942162Z",
          "shell.execute_reply.started": "2022-01-22T15:55:52.933524Z"
        },
        "id": "sCNLuoLYdIAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8cdd05f2-1314-41a0-e897-9d4e49b485e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production. <br /><br />The...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically there's a family where a little boy ...          0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2e5f75c-1334-4688-9d25-d53fb30b5900\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2e5f75c-1334-4688-9d25-d53fb30b5900')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2e5f75c-1334-4688-9d25-d53fb30b5900 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2e5f75c-1334-4688-9d25-d53fb30b5900');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:52.944777Z",
          "iopub.status.busy": "2022-01-22T15:55:52.944484Z",
          "iopub.status.idle": "2022-01-22T15:55:52.951178Z",
          "shell.execute_reply": "2022-01-22T15:55:52.950461Z",
          "shell.execute_reply.started": "2022-01-22T15:55:52.944743Z"
        },
        "id": "B7QZDuWXdIAR"
      },
      "outputs": [],
      "source": [
        "df.columns = ['TEXT_COLUMN_NAME', 'LABEL_COLUMN_NAME']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:52.953080Z",
          "iopub.status.busy": "2022-01-22T15:55:52.952741Z",
          "iopub.status.idle": "2022-01-22T15:55:53.553818Z",
          "shell.execute_reply": "2022-01-22T15:55:53.553120Z",
          "shell.execute_reply.started": "2022-01-22T15:55:52.952969Z"
        },
        "id": "h5NSD4AGdIAS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94900f46-f458-46ad-d1e8-3ace42635fb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7ff22d5894d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\"\"\"\n",
        "Load the spacy model and load the English language model from https://spacy.io/usage/models\n",
        "\"\"\"\n",
        "spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:53.629426Z",
          "iopub.status.busy": "2022-01-22T15:55:53.629143Z",
          "iopub.status.idle": "2022-01-22T15:55:53.637675Z",
          "shell.execute_reply": "2022-01-22T15:55:53.636930Z",
          "shell.execute_reply.started": "2022-01-22T15:55:53.629373Z"
        },
        "id": "jkLVEMCbdIAT"
      },
      "outputs": [],
      "source": [
        "# general Settings\n",
        "\n",
        "RANDOM_SEED = 123\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "VOCABULARY_SIZE = 20000\n",
        "LEARNING_RATE = 0.005\n",
        "BATCH_SIZE = 50\n",
        "NUM_EPOCHS = 20\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "EMBEDDING_DIM = 400\n",
        "HIDDEN_DIM = 256\n",
        "NUM_CLASSES = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi_J1bjmdIAU"
      },
      "source": [
        "# Text & label Preparation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchtext==0.9.0"
      ],
      "metadata": {
        "id": "9gp7Kv1jynmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043b3051-a308-437e-f567-fdae18663b0e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (1.8.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchtext==0.9.0) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:53.639530Z",
          "iopub.status.busy": "2022-01-22T15:55:53.639045Z",
          "iopub.status.idle": "2022-01-22T15:55:54.191068Z",
          "shell.execute_reply": "2022-01-22T15:55:54.190361Z",
          "shell.execute_reply.started": "2022-01-22T15:55:53.639494Z"
        },
        "id": "IZIgLEPDdIAU"
      },
      "outputs": [],
      "source": [
        "# Define feature processing\n",
        "\"\"\"\n",
        "Define the fields for the data.\n",
        "\"\"\"\n",
        "import torch\n",
        "TEXT = torchtext.legacy.data.Field(tokenize = 'spacy', tokenizer_language = 'en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:54.194504Z",
          "iopub.status.busy": "2022-01-22T15:55:54.194231Z",
          "iopub.status.idle": "2022-01-22T15:55:54.198370Z",
          "shell.execute_reply": "2022-01-22T15:55:54.197471Z",
          "shell.execute_reply.started": "2022-01-22T15:55:54.194470Z"
        },
        "id": "aXq26xX_dIAV"
      },
      "outputs": [],
      "source": [
        "# Define Label processing\n",
        "LABEL = torchtext.legacy.data.LabelField(dtype = torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:54.200276Z",
          "iopub.status.busy": "2022-01-22T15:55:54.199959Z",
          "iopub.status.idle": "2022-01-22T15:55:57.099915Z",
          "shell.execute_reply": "2022-01-22T15:55:57.099168Z",
          "shell.execute_reply.started": "2022-01-22T15:55:54.200243Z"
        },
        "id": "RruVm2OwdIAV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c4f00e4f-17e8-4653-b5f5-f4e13ce069c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    TEXT_COLUMN_NAME  LABEL_COLUMN_NAME\n",
              "0  One of the other reviewers has mentioned that ...                  1\n",
              "1  A wonderful little production. <br /><br />The...                  1\n",
              "2  I thought this was a wonderful way to spend ti...                  1\n",
              "3  Basically there's a family where a little boy ...                  0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...                  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efecea53-90ea-4654-bee7-9efdae8bc7be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXT_COLUMN_NAME</th>\n",
              "      <th>LABEL_COLUMN_NAME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efecea53-90ea-4654-bee7-9efdae8bc7be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-efecea53-90ea-4654-bee7-9efdae8bc7be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-efecea53-90ea-4654-bee7-9efdae8bc7be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\"\"\"\n",
        "Define the fields for the data.\n",
        "\"\"\"\n",
        "\n",
        "df.to_csv('moviedata.csv', index = None)\n",
        "df = pd.read_csv('moviedata.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:57.102513Z",
          "iopub.status.busy": "2022-01-22T15:55:57.102056Z",
          "iopub.status.idle": "2022-01-22T15:56:41.889075Z",
          "shell.execute_reply": "2022-01-22T15:56:41.888358Z",
          "shell.execute_reply.started": "2022-01-22T15:55:57.102470Z"
        },
        "id": "U1Obpl7RdIAW"
      },
      "outputs": [],
      "source": [
        "# process the dataset\n",
        "\n",
        "fields = [('TEXT_COLUMN_NAME', TEXT), ('LABEL_COLUMN_NAME', LABEL)]\n",
        "\n",
        "dataset = torchtext.legacy.data.TabularDataset(\n",
        "                    path = '/content/moviedata.csv', \n",
        "                    format = 'csv', \n",
        "                    skip_header = True, \n",
        "                    fields =  fields \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7PHS2OldIAX"
      },
      "source": [
        "# Data Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:41.890714Z",
          "iopub.status.busy": "2022-01-22T15:56:41.890459Z",
          "iopub.status.idle": "2022-01-22T15:56:41.961168Z",
          "shell.execute_reply": "2022-01-22T15:56:41.960371Z",
          "shell.execute_reply.started": "2022-01-22T15:56:41.890680Z"
        },
        "id": "bJ9kFlMzdIAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfbeb98b-982d-4c33-a3e6-e65261385a89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data 40000\n",
            "Length of test data 10000\n"
          ]
        }
      ],
      "source": [
        "# Split dataset into train and test set\n",
        "\n",
        "train_data, test_data = dataset.split(split_ratio = [0.8, 0.2], random_state = random.seed(RANDOM_SEED))\n",
        "\n",
        "print('Length of train data', len(train_data))\n",
        "print('Length of test data', len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:41.962867Z",
          "iopub.status.busy": "2022-01-22T15:56:41.962611Z",
          "iopub.status.idle": "2022-01-22T15:56:42.018970Z",
          "shell.execute_reply": "2022-01-22T15:56:42.017378Z",
          "shell.execute_reply.started": "2022-01-22T15:56:41.962832Z"
        },
        "id": "83MQKvlldIAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1942a243-02b6-4020-b04e-f742f4292205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data 34000\n",
            "Length of valid data 6000\n"
          ]
        }
      ],
      "source": [
        "train_data, val_data = train_data.split(split_ratio = [0.85, 0.15], random_state = random.seed(RANDOM_SEED))\n",
        "\n",
        "print('Length of train data', len(train_data))\n",
        "print('Length of valid data', len(val_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJtv_w3tdIAZ"
      },
      "source": [
        "# Data Observation after Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:42.020384Z",
          "iopub.status.busy": "2022-01-22T15:56:42.020132Z",
          "iopub.status.idle": "2022-01-22T15:56:42.026208Z",
          "shell.execute_reply": "2022-01-22T15:56:42.025377Z",
          "shell.execute_reply.started": "2022-01-22T15:56:42.020349Z"
        },
        "id": "ENTck84gdIAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b19175c-85c1-46e8-cb79-f25d49d8cc05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'TEXT_COLUMN_NAME': ['Flipping', 'through', 'the', 'channels', 'I', 'was', 'lucky', 'enough', 'to', 'stumble', 'upon', 'the', 'beginning', 'of', 'this', 'movie', '.', 'I', 'must', 'admit', 'that', 'it', 'grabbed', 'my', 'attention', 'almost', 'immediately', '.', 'I', 'love', 'older', 'films', 'and', 'this', 'is', 'or', 'should', 'be', 'considered', 'a', 'classic', '!', 'One', 'of', 'the', 'most', 'wonderful', 'rarities', 'of', 'this', 'movie', 'is', 'that', 'the', 'main', 'character', 'was', 'not', 'only', 'female', 'but', 'she', 'was', 'also', 'a', 'bad', 'girl', '.', 'I', 'highly', 'recommend', 'this', 'movie', '!'], 'LABEL_COLUMN_NAME': '1'}\n"
          ]
        }
      ],
      "source": [
        "# Look at first traning example\n",
        "\n",
        "print(vars(train_data.examples[2000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:42.028212Z",
          "iopub.status.busy": "2022-01-22T15:56:42.027904Z",
          "iopub.status.idle": "2022-01-22T15:56:43.688300Z",
          "shell.execute_reply": "2022-01-22T15:56:43.687534Z",
          "shell.execute_reply.started": "2022-01-22T15:56:42.028178Z"
        },
        "id": "_kBPyxNjdIAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eeeae0e-b507-489b-d87d-060038383706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary size: 20002\n",
            "Label Size: 2\n"
          ]
        }
      ],
      "source": [
        "# Build Vocabulary\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = VOCABULARY_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f'vocabulary size: {len(TEXT.vocab)}')\n",
        "print(f'Label Size: {len(LABEL.vocab)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hr_RGIXdIAb"
      },
      "source": [
        " 2 extra value in vocabulary is because added (unknown) and (padding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:43.690179Z",
          "iopub.status.busy": "2022-01-22T15:56:43.689727Z",
          "iopub.status.idle": "2022-01-22T15:56:43.726493Z",
          "shell.execute_reply": "2022-01-22T15:56:43.725793Z",
          "shell.execute_reply.started": "2022-01-22T15:56:43.690127Z"
        },
        "id": "x28sV54-dIAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd2addd-c94b-4952-8cec-15b576b8b14d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 390972), (',', 369444), ('.', 318719), ('a', 210502), ('and', 210006), ('of', 194658), ('to', 180163), ('is', 145895), ('in', 118266), ('I', 105681), ('it', 103588), ('that', 93995), ('\"', 85530), (\"'s\", 83147), ('this', 81771), ('-', 70411), ('/><br', 68787), ('was', 67372), ('as', 57734), ('movie', 57571)]\n"
          ]
        }
      ],
      "source": [
        "# Print the most common words: Use the most_common method of the TEXT vocabulary\n",
        "most_common_words = TEXT.vocab.freqs.most_common(20)\n",
        "print(most_common_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:43.727759Z",
          "iopub.status.busy": "2022-01-22T15:56:43.727533Z",
          "iopub.status.idle": "2022-01-22T15:56:43.733148Z",
          "shell.execute_reply": "2022-01-22T15:56:43.732231Z",
          "shell.execute_reply.started": "2022-01-22T15:56:43.727727Z"
        },
        "id": "r-QegAwTdIAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9928e6cf-694c-4687-b235-be6a8b4bf198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is', 'in', 'I', 'it', 'that', '\"', \"'s\", 'this', '-', '/><br', 'was']\n"
          ]
        }
      ],
      "source": [
        "# Token corresponding to first 10 Indices\n",
        "\n",
        "print(TEXT.vocab.itos[:20]) #itos = Integer to string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edwEq_sVdIAe"
      },
      "source": [
        "# Data Preparation for Batch wise Implimentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:43.760843Z",
          "iopub.status.busy": "2022-01-22T15:56:43.760082Z",
          "iopub.status.idle": "2022-01-22T15:56:43.766731Z",
          "shell.execute_reply": "2022-01-22T15:56:43.766017Z",
          "shell.execute_reply.started": "2022-01-22T15:56:43.760804Z"
        },
        "id": "sDrAULFAdIAe"
      },
      "outputs": [],
      "source": [
        "# Define Dataloader\n",
        "\n",
        "train_loader, valid_loader, test_loader = torchtext.legacy.data.BucketIterator.splits(\n",
        "        (train_data, val_data, test_data),\n",
        "        batch_size = 50,\n",
        "        sort_within_batch = False,\n",
        "        sort_key = lambda x:len(x.TEXT_COLUMN_NAME), \n",
        "        device = DEVICE\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:43.768827Z",
          "iopub.status.busy": "2022-01-22T15:56:43.768197Z",
          "iopub.status.idle": "2022-01-22T15:56:43.900963Z",
          "shell.execute_reply": "2022-01-22T15:56:43.900283Z",
          "shell.execute_reply.started": "2022-01-22T15:56:43.768790Z"
        },
        "id": "-scnNFcidIAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d8b20d-0a05-4f01-99aa-e4d1fc15ff48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "Text matrix size: torch.Size([930, 50])\n",
            "Target vector size: torch.Size([50])\n",
            "\n",
            "Valid:\n",
            "Text matrix size: torch.Size([47, 50])\n",
            "Target vector size: torch.Size([50])\n",
            "\n",
            "Test:\n",
            "Text matrix size: torch.Size([41, 50])\n",
            "Target vector size: torch.Size([50])\n"
          ]
        }
      ],
      "source": [
        "# Testing the iterators (note that the number of rows depends on the longest document in the respective batch):\n",
        "\n",
        "print('Train')\n",
        "for batch in train_loader:\n",
        "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
        "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nValid:')\n",
        "for batch in valid_loader:\n",
        "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
        "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nTest:')\n",
        "for batch in test_loader:\n",
        "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
        "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgWAnfsYdIAg"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:43.910544Z",
          "iopub.status.busy": "2022-01-22T15:56:43.910274Z",
          "iopub.status.idle": "2022-01-22T15:56:43.920687Z",
          "shell.execute_reply": "2022-01-22T15:56:43.919977Z",
          "shell.execute_reply.started": "2022-01-22T15:56:43.910510Z"
        },
        "id": "KVm1Ek6ZdIAg"
      },
      "outputs": [],
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        ### ADD YOUR CODE HERE ###\n",
        "        \n",
        "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = torch.nn.LSTM(embedding_dim, hidden_dim)        \n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "        ### END YOUR CODE ### \n",
        "\n",
        "    def forward(self, text):\n",
        "        ### ADD YOUR CODE HERE ###\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        output,(hidden,cell) = self.rnn(embedded)\n",
        "        hidden.squeeze_(0)\n",
        "        output = self.fc(hidden)\n",
        "        \n",
        "        ### END YOUR CODE ###\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:43.922337Z",
          "iopub.status.busy": "2022-01-22T15:56:43.921742Z",
          "iopub.status.idle": "2022-01-22T15:56:51.579010Z",
          "shell.execute_reply": "2022-01-22T15:56:51.578073Z",
          "shell.execute_reply.started": "2022-01-22T15:56:43.922287Z"
        },
        "id": "14IlvEJ2dIAh"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "model = RNN(input_dim= len(TEXT.vocab), ### ADD YOUR INPUT DIM HERE. This can be the length of your vocabulary or the embedding dim ###\n",
        "            embedding_dim=EMBEDDING_DIM, ### ADD YOUR EMBEDDING DIM HERE ###\n",
        "            hidden_dim=HIDDEN_DIM, ### ADD YOUR HIDDEN DIM HERE ###\n",
        "            output_dim=2  ### ADD NUMBER OF CLASSES HERE ###\n",
        ")\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6wGZvRydIAh"
      },
      "source": [
        "# Define Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:51.581205Z",
          "iopub.status.busy": "2022-01-22T15:56:51.580712Z",
          "iopub.status.idle": "2022-01-22T15:56:51.589897Z",
          "shell.execute_reply": "2022-01-22T15:56:51.588931Z",
          "shell.execute_reply.started": "2022-01-22T15:56:51.581131Z"
        },
        "id": "CsQMacY_dIAh"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        correct_pred, num_examples = 0, 0\n",
        "\n",
        "        for i, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "            features = features.to(device)\n",
        "            targets = targets.float().to(device)\n",
        "\n",
        "            logits = model(features)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OLOYtiDdIAi"
      },
      "source": [
        "# Model Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:51.596066Z",
          "iopub.status.busy": "2022-01-22T15:56:51.595269Z",
          "iopub.status.idle": "2022-01-22T16:41:22.979843Z",
          "shell.execute_reply": "2022-01-22T16:41:22.979001Z",
          "shell.execute_reply.started": "2022-01-22T15:56:51.596024Z"
        },
        "id": "EjzGwEr_dIAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7df3c9a-e16f-4bae-b337-e9803a173fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/020 | Batch 000/680 | Loss: 0.6976\n",
            "Epoch: 001/020 | Batch 050/680 | Loss: 0.6976\n",
            "Epoch: 001/020 | Batch 100/680 | Loss: 0.6899\n",
            "Epoch: 001/020 | Batch 150/680 | Loss: 0.6944\n",
            "Epoch: 001/020 | Batch 200/680 | Loss: 0.6849\n",
            "Epoch: 001/020 | Batch 250/680 | Loss: 0.6940\n",
            "Epoch: 001/020 | Batch 300/680 | Loss: 0.7014\n",
            "Epoch: 001/020 | Batch 350/680 | Loss: 0.6941\n",
            "Epoch: 001/020 | Batch 400/680 | Loss: 0.6894\n",
            "Epoch: 001/020 | Batch 450/680 | Loss: 0.6952\n",
            "Epoch: 001/020 | Batch 500/680 | Loss: 0.7027\n",
            "Epoch: 001/020 | Batch 550/680 | Loss: 0.7238\n",
            "Epoch: 001/020 | Batch 600/680 | Loss: 0.6923\n",
            "Epoch: 001/020 | Batch 650/680 | Loss: 0.6883\n",
            "training accuracy: 50.39%\n",
            "valid accuracy: 49.92%\n",
            "Time elapsed: 1.48 min\n",
            "Epoch: 002/020 | Batch 000/680 | Loss: 0.6871\n",
            "Epoch: 002/020 | Batch 050/680 | Loss: 0.6908\n",
            "Epoch: 002/020 | Batch 100/680 | Loss: 0.6900\n",
            "Epoch: 002/020 | Batch 150/680 | Loss: 0.6970\n",
            "Epoch: 002/020 | Batch 200/680 | Loss: 0.6534\n",
            "Epoch: 002/020 | Batch 250/680 | Loss: 0.6968\n",
            "Epoch: 002/020 | Batch 300/680 | Loss: 0.6983\n",
            "Epoch: 002/020 | Batch 350/680 | Loss: 0.6940\n",
            "Epoch: 002/020 | Batch 400/680 | Loss: 0.6938\n",
            "Epoch: 002/020 | Batch 450/680 | Loss: 0.7067\n",
            "Epoch: 002/020 | Batch 500/680 | Loss: 0.7142\n",
            "Epoch: 002/020 | Batch 550/680 | Loss: 0.6973\n",
            "Epoch: 002/020 | Batch 600/680 | Loss: 0.6945\n",
            "Epoch: 002/020 | Batch 650/680 | Loss: 0.6929\n",
            "training accuracy: 50.49%\n",
            "valid accuracy: 50.12%\n",
            "Time elapsed: 3.02 min\n",
            "Epoch: 003/020 | Batch 000/680 | Loss: 0.6881\n",
            "Epoch: 003/020 | Batch 050/680 | Loss: 0.6982\n",
            "Epoch: 003/020 | Batch 100/680 | Loss: 0.6790\n",
            "Epoch: 003/020 | Batch 150/680 | Loss: 0.7279\n",
            "Epoch: 003/020 | Batch 200/680 | Loss: 0.6850\n",
            "Epoch: 003/020 | Batch 250/680 | Loss: 0.6804\n",
            "Epoch: 003/020 | Batch 300/680 | Loss: 0.6894\n",
            "Epoch: 003/020 | Batch 350/680 | Loss: 0.7159\n",
            "Epoch: 003/020 | Batch 400/680 | Loss: 0.6992\n",
            "Epoch: 003/020 | Batch 450/680 | Loss: 0.6830\n",
            "Epoch: 003/020 | Batch 500/680 | Loss: 0.6965\n",
            "Epoch: 003/020 | Batch 550/680 | Loss: 0.7012\n",
            "Epoch: 003/020 | Batch 600/680 | Loss: 0.6898\n",
            "Epoch: 003/020 | Batch 650/680 | Loss: 0.7081\n",
            "training accuracy: 50.71%\n",
            "valid accuracy: 50.62%\n",
            "Time elapsed: 4.62 min\n",
            "Epoch: 004/020 | Batch 000/680 | Loss: 0.6898\n",
            "Epoch: 004/020 | Batch 050/680 | Loss: 0.6783\n",
            "Epoch: 004/020 | Batch 100/680 | Loss: 0.6859\n",
            "Epoch: 004/020 | Batch 150/680 | Loss: 0.7244\n",
            "Epoch: 004/020 | Batch 200/680 | Loss: 0.6816\n",
            "Epoch: 004/020 | Batch 250/680 | Loss: 0.7030\n",
            "Epoch: 004/020 | Batch 300/680 | Loss: 0.6661\n",
            "Epoch: 004/020 | Batch 350/680 | Loss: 0.6793\n",
            "Epoch: 004/020 | Batch 400/680 | Loss: 0.7242\n",
            "Epoch: 004/020 | Batch 450/680 | Loss: 0.6885\n",
            "Epoch: 004/020 | Batch 500/680 | Loss: 0.6702\n",
            "Epoch: 004/020 | Batch 550/680 | Loss: 0.6720\n",
            "Epoch: 004/020 | Batch 600/680 | Loss: 0.6880\n",
            "Epoch: 004/020 | Batch 650/680 | Loss: 0.6862\n",
            "training accuracy: 55.94%\n",
            "valid accuracy: 54.68%\n",
            "Time elapsed: 6.24 min\n",
            "Epoch: 005/020 | Batch 000/680 | Loss: 0.6767\n",
            "Epoch: 005/020 | Batch 050/680 | Loss: 0.6366\n",
            "Epoch: 005/020 | Batch 100/680 | Loss: 0.6508\n",
            "Epoch: 005/020 | Batch 150/680 | Loss: 0.6629\n",
            "Epoch: 005/020 | Batch 200/680 | Loss: 0.7211\n",
            "Epoch: 005/020 | Batch 250/680 | Loss: 0.6348\n",
            "Epoch: 005/020 | Batch 300/680 | Loss: 0.6953\n",
            "Epoch: 005/020 | Batch 350/680 | Loss: 0.6788\n",
            "Epoch: 005/020 | Batch 400/680 | Loss: 0.7096\n",
            "Epoch: 005/020 | Batch 450/680 | Loss: 0.5995\n",
            "Epoch: 005/020 | Batch 500/680 | Loss: 0.6883\n",
            "Epoch: 005/020 | Batch 550/680 | Loss: 0.6451\n",
            "Epoch: 005/020 | Batch 600/680 | Loss: 0.6556\n",
            "Epoch: 005/020 | Batch 650/680 | Loss: 0.6452\n",
            "training accuracy: 60.96%\n",
            "valid accuracy: 55.93%\n",
            "Time elapsed: 7.86 min\n",
            "Epoch: 006/020 | Batch 000/680 | Loss: 0.5547\n",
            "Epoch: 006/020 | Batch 050/680 | Loss: 0.6716\n",
            "Epoch: 006/020 | Batch 100/680 | Loss: 0.6500\n",
            "Epoch: 006/020 | Batch 150/680 | Loss: 0.6547\n",
            "Epoch: 006/020 | Batch 200/680 | Loss: 0.6371\n",
            "Epoch: 006/020 | Batch 250/680 | Loss: 0.6556\n",
            "Epoch: 006/020 | Batch 300/680 | Loss: 0.5731\n",
            "Epoch: 006/020 | Batch 350/680 | Loss: 0.5951\n",
            "Epoch: 006/020 | Batch 400/680 | Loss: 0.6158\n",
            "Epoch: 006/020 | Batch 450/680 | Loss: 0.6960\n",
            "Epoch: 006/020 | Batch 500/680 | Loss: 0.5879\n",
            "Epoch: 006/020 | Batch 550/680 | Loss: 0.6341\n",
            "Epoch: 006/020 | Batch 600/680 | Loss: 0.7531\n",
            "Epoch: 006/020 | Batch 650/680 | Loss: 0.7100\n",
            "training accuracy: 66.13%\n",
            "valid accuracy: 57.55%\n",
            "Time elapsed: 9.48 min\n",
            "Epoch: 007/020 | Batch 000/680 | Loss: 0.5412\n",
            "Epoch: 007/020 | Batch 050/680 | Loss: 0.5722\n",
            "Epoch: 007/020 | Batch 100/680 | Loss: 0.6440\n",
            "Epoch: 007/020 | Batch 150/680 | Loss: 0.6768\n",
            "Epoch: 007/020 | Batch 200/680 | Loss: 0.5769\n",
            "Epoch: 007/020 | Batch 250/680 | Loss: 0.5867\n",
            "Epoch: 007/020 | Batch 300/680 | Loss: 0.6564\n",
            "Epoch: 007/020 | Batch 350/680 | Loss: 0.6005\n",
            "Epoch: 007/020 | Batch 400/680 | Loss: 0.5879\n",
            "Epoch: 007/020 | Batch 450/680 | Loss: 0.6384\n",
            "Epoch: 007/020 | Batch 500/680 | Loss: 0.6428\n",
            "Epoch: 007/020 | Batch 550/680 | Loss: 0.6382\n",
            "Epoch: 007/020 | Batch 600/680 | Loss: 0.6179\n",
            "Epoch: 007/020 | Batch 650/680 | Loss: 0.6626\n",
            "training accuracy: 66.96%\n",
            "valid accuracy: 57.10%\n",
            "Time elapsed: 11.09 min\n",
            "Epoch: 008/020 | Batch 000/680 | Loss: 0.6076\n",
            "Epoch: 008/020 | Batch 050/680 | Loss: 0.5923\n",
            "Epoch: 008/020 | Batch 100/680 | Loss: 0.6089\n",
            "Epoch: 008/020 | Batch 150/680 | Loss: 0.6575\n",
            "Epoch: 008/020 | Batch 200/680 | Loss: 0.6234\n",
            "Epoch: 008/020 | Batch 250/680 | Loss: 0.6848\n",
            "Epoch: 008/020 | Batch 300/680 | Loss: 0.5716\n",
            "Epoch: 008/020 | Batch 350/680 | Loss: 0.6645\n",
            "Epoch: 008/020 | Batch 400/680 | Loss: 0.5869\n",
            "Epoch: 008/020 | Batch 450/680 | Loss: 0.6378\n",
            "Epoch: 008/020 | Batch 500/680 | Loss: 0.7763\n",
            "Epoch: 008/020 | Batch 550/680 | Loss: 0.6622\n",
            "Epoch: 008/020 | Batch 600/680 | Loss: 0.6123\n",
            "Epoch: 008/020 | Batch 650/680 | Loss: 0.6200\n",
            "training accuracy: 64.15%\n",
            "valid accuracy: 57.50%\n",
            "Time elapsed: 12.71 min\n",
            "Epoch: 009/020 | Batch 000/680 | Loss: 0.5422\n",
            "Epoch: 009/020 | Batch 050/680 | Loss: 0.6553\n",
            "Epoch: 009/020 | Batch 100/680 | Loss: 0.5582\n",
            "Epoch: 009/020 | Batch 150/680 | Loss: 0.5019\n",
            "Epoch: 009/020 | Batch 200/680 | Loss: 0.6195\n",
            "Epoch: 009/020 | Batch 250/680 | Loss: 0.6649\n",
            "Epoch: 009/020 | Batch 300/680 | Loss: 0.7087\n",
            "Epoch: 009/020 | Batch 350/680 | Loss: 0.6168\n",
            "Epoch: 009/020 | Batch 400/680 | Loss: 0.6258\n",
            "Epoch: 009/020 | Batch 450/680 | Loss: 0.5640\n",
            "Epoch: 009/020 | Batch 500/680 | Loss: 0.7500\n",
            "Epoch: 009/020 | Batch 550/680 | Loss: 0.6774\n",
            "Epoch: 009/020 | Batch 600/680 | Loss: 0.6754\n",
            "Epoch: 009/020 | Batch 650/680 | Loss: 0.4986\n",
            "training accuracy: 65.77%\n",
            "valid accuracy: 57.72%\n",
            "Time elapsed: 14.32 min\n",
            "Epoch: 010/020 | Batch 000/680 | Loss: 0.5803\n",
            "Epoch: 010/020 | Batch 050/680 | Loss: 0.5548\n",
            "Epoch: 010/020 | Batch 100/680 | Loss: 0.5747\n",
            "Epoch: 010/020 | Batch 150/680 | Loss: 0.6010\n",
            "Epoch: 010/020 | Batch 200/680 | Loss: 0.6351\n",
            "Epoch: 010/020 | Batch 250/680 | Loss: 0.6002\n",
            "Epoch: 010/020 | Batch 300/680 | Loss: 0.5641\n",
            "Epoch: 010/020 | Batch 350/680 | Loss: 0.6496\n",
            "Epoch: 010/020 | Batch 400/680 | Loss: 0.6365\n",
            "Epoch: 010/020 | Batch 450/680 | Loss: 0.5825\n",
            "Epoch: 010/020 | Batch 500/680 | Loss: 0.5168\n",
            "Epoch: 010/020 | Batch 550/680 | Loss: 0.5636\n",
            "Epoch: 010/020 | Batch 600/680 | Loss: 0.5480\n",
            "Epoch: 010/020 | Batch 650/680 | Loss: 0.5709\n",
            "training accuracy: 69.67%\n",
            "valid accuracy: 60.12%\n",
            "Time elapsed: 15.93 min\n",
            "Epoch: 011/020 | Batch 000/680 | Loss: 0.5345\n",
            "Epoch: 011/020 | Batch 050/680 | Loss: 0.6104\n",
            "Epoch: 011/020 | Batch 100/680 | Loss: 0.5358\n",
            "Epoch: 011/020 | Batch 150/680 | Loss: 0.6325\n",
            "Epoch: 011/020 | Batch 200/680 | Loss: 0.5252\n",
            "Epoch: 011/020 | Batch 250/680 | Loss: 0.6105\n",
            "Epoch: 011/020 | Batch 300/680 | Loss: 0.4798\n",
            "Epoch: 011/020 | Batch 350/680 | Loss: 0.6286\n",
            "Epoch: 011/020 | Batch 400/680 | Loss: 0.5537\n",
            "Epoch: 011/020 | Batch 450/680 | Loss: 0.5498\n",
            "Epoch: 011/020 | Batch 500/680 | Loss: 0.4940\n",
            "Epoch: 011/020 | Batch 550/680 | Loss: 0.5536\n",
            "Epoch: 011/020 | Batch 600/680 | Loss: 0.7376\n",
            "Epoch: 011/020 | Batch 650/680 | Loss: 0.5561\n",
            "training accuracy: 72.35%\n",
            "valid accuracy: 60.57%\n",
            "Time elapsed: 17.54 min\n",
            "Epoch: 012/020 | Batch 000/680 | Loss: 0.5009\n",
            "Epoch: 012/020 | Batch 050/680 | Loss: 0.5200\n",
            "Epoch: 012/020 | Batch 100/680 | Loss: 0.6117\n",
            "Epoch: 012/020 | Batch 150/680 | Loss: 0.5675\n",
            "Epoch: 012/020 | Batch 200/680 | Loss: 0.4774\n",
            "Epoch: 012/020 | Batch 250/680 | Loss: 0.5843\n",
            "Epoch: 012/020 | Batch 300/680 | Loss: 0.5595\n",
            "Epoch: 012/020 | Batch 350/680 | Loss: 0.6323\n",
            "Epoch: 012/020 | Batch 400/680 | Loss: 0.6850\n",
            "Epoch: 012/020 | Batch 450/680 | Loss: 0.6358\n",
            "Epoch: 012/020 | Batch 500/680 | Loss: 0.6415\n",
            "Epoch: 012/020 | Batch 550/680 | Loss: 0.6667\n",
            "Epoch: 012/020 | Batch 600/680 | Loss: 0.5857\n",
            "Epoch: 012/020 | Batch 650/680 | Loss: 0.5386\n",
            "training accuracy: 75.06%\n",
            "valid accuracy: 62.33%\n",
            "Time elapsed: 19.16 min\n",
            "Epoch: 013/020 | Batch 000/680 | Loss: 0.5656\n",
            "Epoch: 013/020 | Batch 050/680 | Loss: 0.4613\n",
            "Epoch: 013/020 | Batch 100/680 | Loss: 0.4886\n",
            "Epoch: 013/020 | Batch 150/680 | Loss: 0.5903\n",
            "Epoch: 013/020 | Batch 200/680 | Loss: 0.4984\n",
            "Epoch: 013/020 | Batch 250/680 | Loss: 0.4626\n",
            "Epoch: 013/020 | Batch 300/680 | Loss: 0.4573\n",
            "Epoch: 013/020 | Batch 350/680 | Loss: 0.4807\n",
            "Epoch: 013/020 | Batch 400/680 | Loss: 0.5100\n",
            "Epoch: 013/020 | Batch 450/680 | Loss: 0.5477\n",
            "Epoch: 013/020 | Batch 500/680 | Loss: 0.6860\n",
            "Epoch: 013/020 | Batch 550/680 | Loss: 0.4559\n",
            "Epoch: 013/020 | Batch 600/680 | Loss: 0.4931\n",
            "Epoch: 013/020 | Batch 650/680 | Loss: 0.5979\n",
            "training accuracy: 77.19%\n",
            "valid accuracy: 62.32%\n",
            "Time elapsed: 20.77 min\n",
            "Epoch: 014/020 | Batch 000/680 | Loss: 0.5290\n",
            "Epoch: 014/020 | Batch 050/680 | Loss: 0.4052\n",
            "Epoch: 014/020 | Batch 100/680 | Loss: 0.4752\n",
            "Epoch: 014/020 | Batch 150/680 | Loss: 0.3847\n",
            "Epoch: 014/020 | Batch 200/680 | Loss: 0.4200\n",
            "Epoch: 014/020 | Batch 250/680 | Loss: 0.6790\n",
            "Epoch: 014/020 | Batch 300/680 | Loss: 0.4326\n",
            "Epoch: 014/020 | Batch 350/680 | Loss: 0.6538\n",
            "Epoch: 014/020 | Batch 400/680 | Loss: 0.3927\n",
            "Epoch: 014/020 | Batch 450/680 | Loss: 0.4019\n",
            "Epoch: 014/020 | Batch 500/680 | Loss: 0.4894\n",
            "Epoch: 014/020 | Batch 550/680 | Loss: 0.4925\n",
            "Epoch: 014/020 | Batch 600/680 | Loss: 0.4983\n",
            "Epoch: 014/020 | Batch 650/680 | Loss: 0.4661\n",
            "training accuracy: 77.93%\n",
            "valid accuracy: 62.60%\n",
            "Time elapsed: 22.39 min\n",
            "Epoch: 015/020 | Batch 000/680 | Loss: 0.4349\n",
            "Epoch: 015/020 | Batch 050/680 | Loss: 0.5346\n",
            "Epoch: 015/020 | Batch 100/680 | Loss: 0.5869\n",
            "Epoch: 015/020 | Batch 150/680 | Loss: 0.5463\n",
            "Epoch: 015/020 | Batch 200/680 | Loss: 0.5836\n",
            "Epoch: 015/020 | Batch 250/680 | Loss: 0.3712\n",
            "Epoch: 015/020 | Batch 300/680 | Loss: 0.4361\n",
            "Epoch: 015/020 | Batch 350/680 | Loss: 0.5487\n",
            "Epoch: 015/020 | Batch 400/680 | Loss: 0.4355\n",
            "Epoch: 015/020 | Batch 450/680 | Loss: 0.5187\n",
            "Epoch: 015/020 | Batch 500/680 | Loss: 0.4067\n",
            "Epoch: 015/020 | Batch 550/680 | Loss: 0.3646\n",
            "Epoch: 015/020 | Batch 600/680 | Loss: 0.5542\n",
            "Epoch: 015/020 | Batch 650/680 | Loss: 0.5080\n",
            "training accuracy: 80.06%\n",
            "valid accuracy: 63.87%\n",
            "Time elapsed: 23.99 min\n",
            "Epoch: 016/020 | Batch 000/680 | Loss: 0.4034\n",
            "Epoch: 016/020 | Batch 050/680 | Loss: 0.5037\n",
            "Epoch: 016/020 | Batch 100/680 | Loss: 0.4572\n",
            "Epoch: 016/020 | Batch 150/680 | Loss: 0.3576\n",
            "Epoch: 016/020 | Batch 200/680 | Loss: 0.5043\n",
            "Epoch: 016/020 | Batch 250/680 | Loss: 0.3520\n",
            "Epoch: 016/020 | Batch 300/680 | Loss: 0.4901\n",
            "Epoch: 016/020 | Batch 350/680 | Loss: 0.5118\n",
            "Epoch: 016/020 | Batch 400/680 | Loss: 0.4646\n",
            "Epoch: 016/020 | Batch 450/680 | Loss: 0.5293\n",
            "Epoch: 016/020 | Batch 500/680 | Loss: 0.5501\n",
            "Epoch: 016/020 | Batch 550/680 | Loss: 0.6349\n",
            "Epoch: 016/020 | Batch 600/680 | Loss: 0.3821\n",
            "Epoch: 016/020 | Batch 650/680 | Loss: 0.6317\n",
            "training accuracy: 80.95%\n",
            "valid accuracy: 63.90%\n",
            "Time elapsed: 25.60 min\n",
            "Epoch: 017/020 | Batch 000/680 | Loss: 0.3417\n",
            "Epoch: 017/020 | Batch 050/680 | Loss: 0.4358\n",
            "Epoch: 017/020 | Batch 100/680 | Loss: 0.4621\n",
            "Epoch: 017/020 | Batch 150/680 | Loss: 0.3966\n",
            "Epoch: 017/020 | Batch 200/680 | Loss: 0.4787\n",
            "Epoch: 017/020 | Batch 250/680 | Loss: 0.5590\n",
            "Epoch: 017/020 | Batch 300/680 | Loss: 0.3693\n",
            "Epoch: 017/020 | Batch 350/680 | Loss: 0.4394\n",
            "Epoch: 017/020 | Batch 400/680 | Loss: 0.5329\n",
            "Epoch: 017/020 | Batch 450/680 | Loss: 0.4784\n",
            "Epoch: 017/020 | Batch 500/680 | Loss: 0.3637\n",
            "Epoch: 017/020 | Batch 550/680 | Loss: 0.4323\n",
            "Epoch: 017/020 | Batch 600/680 | Loss: 0.3894\n",
            "Epoch: 017/020 | Batch 650/680 | Loss: 0.5292\n",
            "training accuracy: 82.46%\n",
            "valid accuracy: 63.07%\n",
            "Time elapsed: 27.21 min\n",
            "Epoch: 018/020 | Batch 000/680 | Loss: 0.3832\n",
            "Epoch: 018/020 | Batch 050/680 | Loss: 0.3574\n",
            "Epoch: 018/020 | Batch 100/680 | Loss: 0.5853\n",
            "Epoch: 018/020 | Batch 150/680 | Loss: 0.4020\n",
            "Epoch: 018/020 | Batch 200/680 | Loss: 0.4573\n",
            "Epoch: 018/020 | Batch 250/680 | Loss: 0.3842\n",
            "Epoch: 018/020 | Batch 300/680 | Loss: 0.4306\n",
            "Epoch: 018/020 | Batch 350/680 | Loss: 0.4048\n",
            "Epoch: 018/020 | Batch 400/680 | Loss: 0.4135\n",
            "Epoch: 018/020 | Batch 450/680 | Loss: 0.4741\n",
            "Epoch: 018/020 | Batch 500/680 | Loss: 0.5360\n",
            "Epoch: 018/020 | Batch 550/680 | Loss: 0.3007\n",
            "Epoch: 018/020 | Batch 600/680 | Loss: 0.5177\n",
            "Epoch: 018/020 | Batch 650/680 | Loss: 0.4948\n",
            "training accuracy: 83.08%\n",
            "valid accuracy: 63.05%\n",
            "Time elapsed: 28.82 min\n",
            "Epoch: 019/020 | Batch 000/680 | Loss: 0.4347\n",
            "Epoch: 019/020 | Batch 050/680 | Loss: 0.4726\n",
            "Epoch: 019/020 | Batch 100/680 | Loss: 0.4683\n",
            "Epoch: 019/020 | Batch 150/680 | Loss: 0.3595\n",
            "Epoch: 019/020 | Batch 200/680 | Loss: 0.4019\n",
            "Epoch: 019/020 | Batch 250/680 | Loss: 0.4394\n",
            "Epoch: 019/020 | Batch 300/680 | Loss: 0.3877\n",
            "Epoch: 019/020 | Batch 350/680 | Loss: 0.3589\n",
            "Epoch: 019/020 | Batch 400/680 | Loss: 0.4375\n",
            "Epoch: 019/020 | Batch 450/680 | Loss: 0.3108\n",
            "Epoch: 019/020 | Batch 500/680 | Loss: 0.5846\n",
            "Epoch: 019/020 | Batch 550/680 | Loss: 0.3418\n",
            "Epoch: 019/020 | Batch 600/680 | Loss: 0.3577\n",
            "Epoch: 019/020 | Batch 650/680 | Loss: 0.4024\n",
            "training accuracy: 84.11%\n",
            "valid accuracy: 63.85%\n",
            "Time elapsed: 30.43 min\n",
            "Epoch: 020/020 | Batch 000/680 | Loss: 0.3575\n",
            "Epoch: 020/020 | Batch 050/680 | Loss: 0.3658\n",
            "Epoch: 020/020 | Batch 100/680 | Loss: 0.3403\n",
            "Epoch: 020/020 | Batch 150/680 | Loss: 0.4975\n",
            "Epoch: 020/020 | Batch 200/680 | Loss: 0.3976\n",
            "Epoch: 020/020 | Batch 250/680 | Loss: 0.3779\n",
            "Epoch: 020/020 | Batch 300/680 | Loss: 0.3384\n",
            "Epoch: 020/020 | Batch 350/680 | Loss: 0.3157\n",
            "Epoch: 020/020 | Batch 400/680 | Loss: 0.3561\n",
            "Epoch: 020/020 | Batch 450/680 | Loss: 0.4503\n",
            "Epoch: 020/020 | Batch 500/680 | Loss: 0.4960\n",
            "Epoch: 020/020 | Batch 550/680 | Loss: 0.3851\n",
            "Epoch: 020/020 | Batch 600/680 | Loss: 0.3575\n",
            "Epoch: 020/020 | Batch 650/680 | Loss: 0.5204\n",
            "training accuracy: 84.68%\n",
            "valid accuracy: 63.70%\n",
            "Time elapsed: 32.04 min\n",
            "Total Training Time: 32.04 min\n",
            "Test accuracy: 64.32%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    for batch_idx, batch_data in enumerate(train_loader):\n",
        "        \n",
        "        text = batch_data.TEXT_COLUMN_NAME.to(DEVICE)\n",
        "        labels = batch_data.LABEL_COLUMN_NAME.to(DEVICE)\n",
        "\n",
        "        pred = model(text)\n",
        "        loss = torch.nn.functional.cross_entropy(pred, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if not batch_idx % 50:\n",
        "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
        "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
        "                   f'Loss: {loss:.4f}')\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        print(f'training accuracy: '\n",
        "              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n",
        "              f'\\nvalid accuracy: '\n",
        "              f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
        "        \n",
        "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
        "    \n",
        "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
        "print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsSsgs07dIAj"
      },
      "source": [
        "# Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T16:41:22.981494Z",
          "iopub.status.busy": "2022-01-22T16:41:22.981224Z",
          "iopub.status.idle": "2022-01-22T16:41:23.185798Z",
          "shell.execute_reply": "2022-01-22T16:41:23.185126Z",
          "shell.execute_reply.started": "2022-01-22T16:41:22.981459Z"
        },
        "id": "NtjLgOWcdIAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34520680-1264-4399-c118-67edc045f6c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability positive:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45970046520233154"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.nn.functional.softmax(model(tensor), dim=1)\n",
        "    return prediction[0][1].item()\n",
        "\n",
        "print('Probability positive:')\n",
        "predict_sentiment(model, \"This is such an awesome movie, I really love it!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T16:41:49.753493Z",
          "iopub.status.busy": "2022-01-22T16:41:49.752937Z",
          "iopub.status.idle": "2022-01-22T16:41:49.762087Z",
          "shell.execute_reply": "2022-01-22T16:41:49.761053Z",
          "shell.execute_reply.started": "2022-01-22T16:41:49.753453Z"
        },
        "id": "R8zHfzhvdIAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b3365b3-8f4f-43f7-c32f-9694c78b097f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability positive:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.033389680087566376"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "print('Probability positive:')\n",
        "predict_sentiment(model, \"I really hate this movie. It is really bad and sucks!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LGWqUlm3dIAl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "coding_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}